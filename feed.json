{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "Benoit Tigeot&#39;s blog",
	"language": "en",
	"home_page_url": "https://benoittgt.github.io/",
	"feed_url": "https://benoittgt.github.io/feed.json",
	"description": "Ruby on Rails, PostgreSQL, and more.",
	"author": {
		"name": "Benoit Tigeot",
		"url": "https://benoittgt.github.io/about"
	},
	"items": [
		{
			"id": "https://benoittgt.github.io/blog/postgres_measuring_lock/",
			"url": "https://benoittgt.github.io/blog/postgres_measuring_lock/",
			"title": "Measuring SELECT ... FOR UPDATE Latency in PostgreSQL",
			"content_html": "<p>At <a href=\"https://www.lifen.fr/\">Lifen</a>, we love digging into database performance issues. Recently, while monitoring one of our Rails applications using PgAnalyze and specific logging, we noticed something concerning: around <strong>13‚Äì16% of a basic but frequently run query</strong> was taking more than 100ms to complete‚Ä¶ and sometimes up to 1500ms. The culprit? <code>SELECT ... FOR UPDATE</code> queries that were experiencing intermittent slowdowns. The average time was normally 6ms.</p>\n<h3 id=\"slow-lock-acquisition\" tabindex=\"-1\">Slow lock <strong>acquisition</strong> ? <a class=\"header-anchor\" href=\"https://benoittgt.github.io/blog/postgres_measuring_lock/\">#</a></h3>\n<p><code>SELECT ... FOR UPDATE</code> <a href=\"https://www.postgresql.org/docs/current/sql-select.html\">is used to acquire a lock</a> on row during a transaction. We use it to prevent concurrent async tasks from modifying the same row. This can happen, for example, when consuming lots of events from a queue system with an ‚Äúat least once‚Äù delivery guarantee.</p>\n<p>The obvious question was: <em>Are these queries slow because they‚Äôre waiting to acquire locks, or because they‚Äôre taking a long time to find the actual rows?</em></p>\n<p>This distinction matters a lot. If it‚Äôs <strong>lock contention</strong>, we need to optimize our locking strategy. If it‚Äôs <strong>row lookup performance</strong>, we need better indexes or query optimizations.</p>\n<p>PostgreSQL's built-in <code>log_lock_waits</code> parameter seemed like the natural solution, but it requires setting a low <code>deadlock_timeout</code>, which makes it impractical for production environments. We needed a different approach.</p>\n<p>From the doc on <code>log_lock_waits</code></p>\n<blockquote>\n<p>Controls whether a log message is produced when a session waits longer than <a href=\"https://www.postgresql.org/docs/17/runtime-config-locks.html#GUC-DEADLOCK-TIMEOUT\"><strong>deadlock_timeout</strong></a> to acquire a lock.</p>\n</blockquote>\n<h3 id=\"measuring\" tabindex=\"-1\">Measuring <a class=\"header-anchor\" href=\"https://benoittgt.github.io/blog/postgres_measuring_lock/\">#</a></h3>\n<p>To distinguish between lock acquisition time and row lookup time, we replaced the <code>FOR UPDATE</code> with a <code>pg_advisory_xact_lock</code>, then monitored both parts of the query separately.</p>\n<p>The SQL transformation looked like this:</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- Original</span>\n<span class=\"token keyword\">BEGIN</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">SELECT</span> id <span class=\"token keyword\">FROM</span> steps <span class=\"token keyword\">WHERE</span> id <span class=\"token operator\">=</span> <span class=\"token number\">123</span>_456 <span class=\"token keyword\">FOR</span> <span class=\"token keyword\">UPDATE</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- this is sometime slow</span>\n<span class=\"token keyword\">UPDATE</span> <span class=\"token keyword\">status</span> <span class=\"token operator\">=</span> <span class=\"token string\">'in_progress'</span> <span class=\"token keyword\">FROM</span> steps <span class=\"token keyword\">WHERE</span> id <span class=\"token operator\">=</span> <span class=\"token number\">123</span>_456<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">COMMIT</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Temporary new version</span>\n<span class=\"token keyword\">BEGIN</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">SELECT</span> pg_advisory_xact_lock<span class=\"token punctuation\">(</span>hashtext<span class=\"token punctuation\">(</span><span class=\"token string\">'update step status'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> hashtext<span class=\"token punctuation\">(</span><span class=\"token string\">'123456'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">UPDATE</span> steps <span class=\"token keyword\">SET</span> <span class=\"token keyword\">status</span> <span class=\"token operator\">=</span> <span class=\"token string\">'in_progress'</span> <span class=\"token keyword\">WHERE</span> id <span class=\"token operator\">=</span> <span class=\"token number\">123</span>_456<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">COMMIT</span><span class=\"token punctuation\">;</span></code></pre>\n<p>And in the Rails app:</p>\n<pre class=\"language-ruby\" tabindex=\"0\"><code class=\"language-ruby\"><span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">process_with_xact_lock</span></span><span class=\"token punctuation\">(</span>step_id<span class=\"token punctuation\">)</span>\n  start_time <span class=\"token operator\">=</span> <span class=\"token builtin\">Time</span><span class=\"token punctuation\">.</span>current\n  hash_key <span class=\"token operator\">=</span> <span class=\"token string-literal\"><span class=\"token string\">\"step:</span><span class=\"token interpolation\"><span class=\"token delimiter punctuation\">#{</span><span class=\"token content\">step_id</span><span class=\"token delimiter punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">.</span>abs\n\n  ActiveRecord<span class=\"token double-colon punctuation\">::</span>Base<span class=\"token punctuation\">.</span>transaction <span class=\"token keyword\">do</span>\n    connection<span class=\"token punctuation\">.</span>select_all<span class=\"token punctuation\">(</span><span class=\"token string-literal\"><span class=\"token string\">\"SELECT pg_advisory_xact_lock(</span><span class=\"token interpolation\"><span class=\"token delimiter punctuation\">#{</span><span class=\"token content\">connection<span class=\"token punctuation\">.</span>quote<span class=\"token punctuation\">(</span>hash_key<span class=\"token punctuation\">)</span></span><span class=\"token delimiter punctuation\">}</span></span><span class=\"token string\">)\"</span></span><span class=\"token punctuation\">)</span>\n    lock_duration <span class=\"token operator\">=</span> <span class=\"token builtin\">Time</span><span class=\"token punctuation\">.</span>current <span class=\"token operator\">-</span> start_time\n\n    query_start <span class=\"token operator\">=</span> <span class=\"token builtin\">Time</span><span class=\"token punctuation\">.</span>current\n    step <span class=\"token operator\">=</span> Step<span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span>step_id<span class=\"token punctuation\">)</span>\n    query_duration <span class=\"token operator\">=</span> <span class=\"token builtin\">Time</span><span class=\"token punctuation\">.</span>current <span class=\"token operator\">-</span> query_start\n\n    step<span class=\"token punctuation\">.</span>update<span class=\"token operator\">!</span><span class=\"token punctuation\">(</span><span class=\"token symbol\">status</span><span class=\"token operator\">:</span> <span class=\"token string-literal\"><span class=\"token string\">'in_progress'</span></span><span class=\"token punctuation\">)</span>\n\n    log_timing<span class=\"token punctuation\">(</span>step_id<span class=\"token punctuation\">,</span> lock_duration<span class=\"token punctuation\">,</span> query_duration<span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> slow_operation<span class=\"token operator\">?</span><span class=\"token punctuation\">(</span>lock_duration<span class=\"token punctuation\">,</span> query_duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># ...</span>\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span>\n\n<span class=\"token keyword\">private</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">slow_operation</span></span><span class=\"token operator\">?</span><span class=\"token punctuation\">(</span>lock_time<span class=\"token punctuation\">,</span> query_time<span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">(</span>lock_time <span class=\"token operator\">+</span> query_time<span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0.1</span> <span class=\"token comment\"># 100ms threshold</span>\n<span class=\"token keyword\">end</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">log_timing</span></span><span class=\"token punctuation\">(</span>id<span class=\"token punctuation\">,</span> lock_ms<span class=\"token punctuation\">,</span> query_ms<span class=\"token punctuation\">)</span>\n  Rails<span class=\"token punctuation\">.</span>logger<span class=\"token punctuation\">.</span>warn<span class=\"token punctuation\">(</span>\n    <span class=\"token string-literal\"><span class=\"token string\">\"Slow operation: id=</span><span class=\"token interpolation\"><span class=\"token delimiter punctuation\">#{</span><span class=\"token content\">id</span><span class=\"token delimiter punctuation\">}</span></span><span class=\"token string\"> lock=</span><span class=\"token interpolation\"><span class=\"token delimiter punctuation\">#{</span><span class=\"token content\"><span class=\"token punctuation\">(</span>lock_ms<span class=\"token operator\">*</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>round</span><span class=\"token delimiter punctuation\">}</span></span><span class=\"token string\">ms query=</span><span class=\"token interpolation\"><span class=\"token delimiter punctuation\">#{</span><span class=\"token content\"><span class=\"token punctuation\">(</span>query_ms<span class=\"token operator\">*</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>round</span><span class=\"token delimiter punctuation\">}</span></span><span class=\"token string\">ms\"</span></span>\n  <span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">end</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">connection</span></span> <span class=\"token operator\">=</span> ActiveRecord<span class=\"token double-colon punctuation\">::</span>Base<span class=\"token punctuation\">.</span>connection\n</code></pre>\n<p>The code is not bulletproof, but we only used it for a short period to gather data. We knew the chance of lock issues was low, and it was acceptable for this part of the application.</p>\n<h3 id=\"what-we-learned\" tabindex=\"-1\"><strong>What we learned</strong> <a class=\"header-anchor\" href=\"https://benoittgt.github.io/blog/postgres_measuring_lock/\">#</a></h3>\n<p>The results were interesting: when we experienced slowdowns with <code>SELECT ... FOR UPDATE</code>, we <strong>also</strong> saw slowness with the new <code>pg_advisory_xact_lock</code> version both on <strong>lock acquisition</strong> and <strong>row lookup</strong>.</p>\n<p>So, <strong>latency is global</strong>, not specific to one part of the mechanism. That means we needed to look into other database activity that could be causing this broader slowdown.</p>\n<p>In our case, it appeared related to heavy DML activity and <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/wait-event.iowalwrite.html\">IO:WALWrite</a>. To mitigate this, we‚Äôre now looking at reducing the number of INSERT and UPDATE queries by grouping them.</p>\n<h3 id=\"key-takeaways\" tabindex=\"-1\">Key Takeaways <a class=\"header-anchor\" href=\"https://benoittgt.github.io/blog/postgres_measuring_lock/\">#</a></h3>\n<ol>\n<li><strong>Separate concerns when debugging</strong>: Don't assume slow <code>SELECT ... FOR UPDATE</code> means lock contention. Measure lock acquisition and query execution independently.</li>\n<li><strong>Production-friendly monitoring</strong>: This technique works in production without requiring changes to PostgreSQL configuration like <code>deadlock_timeout</code>. We hope that it will be possible to let PostgreSQL report this by itself (see <a href=\"https://www.postgresql.org/message-id/flat/b8b8502915e50f44deb111bc0b43a99e2733e117.camel%40cybertec.at\">discussion on pg-hackers</a>)</li>\n<li>pg_advisory_xact_lock is a great tool for precise, manual locking.</li>\n</ol>\n<p>If you‚Äôre experiencing similar issues with SELECT ... FOR UPDATE, first check your logs, database metrics, and DML activity. Then try this measurement approach, you might discover, like we did, that the real bottleneck is elsewhere.</p>\n<hr>\n<p><em>Thanks to the PostgreSQL community on Slack for the debugging suggestions that led to this technique.</em></p>\n",
			"date_published": "2025-07-28T00:00:00Z"
		}
		,
		{
			"id": "https://benoittgt.github.io/blog/postgres_17_rails/",
			"url": "https://benoittgt.github.io/blog/postgres_17_rails/",
			"title": "As Rails developers, why we are excited about PostgreSQL 17",
			"content_html": "<p>At the time of writing this article, PostgreSQL 17 is nearly out. <a href=\"https://www.postgresql.org/about/news/postgresql-17-rc1-released-2926/\">On September 5th, the first release candidate was published</a>. The final release is expected on September 26th, but we can already explain why we‚Äôve been eagerly awaiting this release since 1 year.</p>\n<p>At <a href=\"https://www.lifen.fr/\">Lifen</a>, we‚Äôve loved Rails from the beginning. We have several Rails applications, each with different scopes and teams, all using PostgreSQL as the main database. Some of these applications handle a significant amount of traffic, and their databases need to be properly monitored. This is done by the infrastructure team and the developers themselves using PgAnalyze, Grafana and sometimes AWS console with &quot;Performance Insight&quot;.</p>\n<p>More than a year ago, we started monitoring the 95th and 99th percentile response times (p95, p99) on an endpoint that was experiencing timeouts. These p99 times were important because they involved a client with significantly more data. While investigating the queries in AppSignal, we quickly found that the issue was on the database side, as is often the case.</p>\n<p>The problematic query involved one table with over 40 GB of data, which was heavily distributed. The query in Rails looked like this:</p>\n<pre class=\"language-ruby\" tabindex=\"0\"><code class=\"language-ruby\">Doc<span class=\"token punctuation\">.</span>where<span class=\"token punctuation\">(</span><span class=\"token symbol\">status</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string-literal\"><span class=\"token string\">'draft'</span></span><span class=\"token punctuation\">,</span><span class=\"token string-literal\"><span class=\"token string\">'sent'</span></span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token symbol\">sender_reference</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string-literal\"><span class=\"token string\">'Client/1'</span></span><span class=\"token punctuation\">,</span> <span class=\"token string-literal\"><span class=\"token string\">'Client/2'</span></span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>order<span class=\"token punctuation\">(</span><span class=\"token symbol\">sent_at</span><span class=\"token operator\">:</span> <span class=\"token symbol\">:desc</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>limit<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></code></pre>\n<p>Pretty simple, right?</p>\n<p>Due to the nature of ActiveRecord DSL, this is something you see often, but without fully understanding the limitations of the underlying database. And those limitations can be surprising.</p>\n<p>When fetching many documents, the query was very slow. We looked at the EXPLAIN plans and quickly identified the issue: <strong>not all indexes were being used.</strong></p>\n<p>You see plan like this one</p>\n<pre class=\"language-markdown\" tabindex=\"0\"><code class=\"language-markdown\">  ->  Index Scan using docs_sent_at_idx on public.docs  (cost=0.56..39748945.58 rows=29744 width=38) (actual time=116.924..218.784 rows=20 loops=1)\n        Output: id, type, status, sender_reference, sent_at, created_at\n        Filter: (((docs.status)::text = ANY ('{draft,sent}'::text[])) AND ((docs.sender_reference)::text = ANY ('{Client/1,Client/2}'::text[])))\n        Rows Removed by Filter: 46354\n        Buffers: shared hit=1421 read=45046</code></pre>\n<p>Index is used but you still need to perform expensive filtering.</p>\n<p>After some exchanges with some great folks on the PostgreSQL Slack, it was mentioned that <strong>PostgreSQL is not optimized for queries with multiple IN or ANY query parameters</strong>. This was a problem, as such queries are common in Rails applications and aren‚Äôt easily optimized using indexes in PostgreSQL. But then, something unexpected happened‚Ä¶</p>\n<p>I received a private message from <a href=\"https://github.com/petergeoghegan\">Peter Geoghegan</a>. He was working on a patch that could help solve my issue. I tested the first version, then a second, and the results were very impressive, with a 90% reduction in query time (from 110ms to 10ms for some data). Indexes were fully utilized.</p>\n<p>The patch is well explained <a href=\"https://pganalyze.com/blog/5mins-postgres-17-faster-btree-index-scans\">in a blog post on PgAnalyze</a> but the changelog entry speaks for itself: ‚ÄúAllow B-tree indexes to more efficiently find a set of values, such as those supplied by IN clauses using constants.‚Äù</p>\n<p>Many iterations were made on this patch. I provided feedback on the PostgreSQL hackers <a href=\"https://www.postgresql.org/message-id/flat/CAHUgstCm94QCN3hrLgU9SkVxhLiuh2G_HsksffZwZWHhzJEreg%40mail.gmail.com#f3af55f2367f6477256fcea40ce586a8\">mailing list</a>, explaining why I, as a developer, was interested in this patch, along with benchmarks and execution plan outputs. The patch was included in PostgreSQL 17 beta, and additional fixes were added.</p>\n<p>With RC1 and a basic Rails application, here‚Äôs the improvement we saw:\nWe inserted 100 million rows into a table with three columns. This was done via SQL, but it could have been done in Rails as well.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token keyword\">INSERT</span> <span class=\"token keyword\">INTO</span>\n  docs <span class=\"token punctuation\">(</span><span class=\"token keyword\">status</span><span class=\"token punctuation\">,</span> sender_reference<span class=\"token punctuation\">,</span> sent_at<span class=\"token punctuation\">,</span> created_at<span class=\"token punctuation\">,</span> updated_at<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">SELECT</span>\n  <span class=\"token punctuation\">(</span><span class=\"token string\">'{sent,draft,suspended}'</span>::<span class=\"token keyword\">text</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>ceil<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">(</span><span class=\"token string\">'{Custom,Client}'</span>::<span class=\"token keyword\">text</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>ceil<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">||</span> <span class=\"token string\">'/'</span> <span class=\"token operator\">||</span> floor<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">(</span>LOCALTIMESTAMP <span class=\"token operator\">-</span> <span class=\"token keyword\">interval</span> <span class=\"token string\">'2 years'</span> <span class=\"token operator\">*</span> random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>::timestamptz<span class=\"token punctuation\">,</span>\n  LOCALTIMESTAMP<span class=\"token punctuation\">,</span>\n  LOCALTIMESTAMP\n<span class=\"token keyword\">FROM</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">100</span>_000_000<span class=\"token punctuation\">)</span> g<span class=\"token punctuation\">;</span></code></pre>\n<p>Those columns are indexed with a multicolumn index.</p>\n<pre class=\"language-ruby\" tabindex=\"0\"><code class=\"language-ruby\">add_index <span class=\"token symbol\">:docs</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token symbol\">:sender_reference</span><span class=\"token punctuation\">,</span> <span class=\"token symbol\">:status</span><span class=\"token punctuation\">,</span> <span class=\"token symbol\">:sent_at</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token symbol\">algorithm</span><span class=\"token operator\">:</span> <span class=\"token symbol\">:concurrently</span></code></pre>\n<p>With PostgreSQL 16 on a Rails 7.2 app, after several queries and with a warm cache, the response time was:</p>\n<blockquote>\n<p>Query executed in 8.45 seconds.</p>\n</blockquote>\n<p>With PostgreSQL 17, the result is ü•Å:</p>\n<blockquote>\n<p>Query executed in 0.11 seconds.</p>\n</blockquote>\n<p>The query can still be optimized to get closer to 10ms, but the most challenging part to optimize has already been addressed by the patch.</p>\n<p>With results like these, I highly encourage you to upgrade to PostgreSQL 17. There are many <a href=\"https://www.postgresql.org/docs/17/release-17.html\">other improvements</a> as well. I also recommend digging deeper into the database side of your application, as this is often the key to faster response times. I‚Äôve learned that developers are welcome to share their feedback on the PostgreSQL hackers‚Äô mailing list, providing benchmarks and feedback as end users.</p>\n<p>Thanks to Peter Geoghegan, Matthias van de Meent, Hubert Depesz, Ants Aasma, and the rest of the PostgreSQL community for their work over the past year.</p>\n<p>If you‚Äôd like to follow the benchmarks made since last year, there is a <a href=\"https://gist.github.com/benoittgt/ab72dc4cfedea2a0c6a5ee809d16e04d\">gist</a>. You can also find the Rails app used to test response times <a href=\"https://github.com/benoittgt/thanks-peter\">on Github</a>.</p>\n",
			"date_published": "2024-09-19T00:00:00Z"
		}
		
	]
}
